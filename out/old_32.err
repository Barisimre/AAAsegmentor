	Adding anaconda3 2022.05 to your environment
	Adding nVidia Cuda Toolkit 11.7
<class 'monai.transforms.utility.array.AddChannel'>: Class `AddChannel` has been deprecated since version 0.8. please use MetaTensor data type and monai.transforms.EnsureChannelFirst instead.
<class 'monai.transforms.utility.array.AsChannelFirst'>: Class `AsChannelFirst` has been deprecated since version 0.8. please use MetaTensor data type and monai.transforms.EnsureChannelFirst instead.
wandb: Currently logged in as: barisimre. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /local/210406/wandb/run-20230508_230610-nyle3s48
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run old_32_512
wandb: ‚≠êÔ∏è View project at https://wandb.ai/barisimre/Meeting
wandb: üöÄ View run at https://wandb.ai/barisimre/Meeting/runs/nyle3s48
Loading dataset:   0%|          | 0/70 [00:00<?, ?it/s]Loading dataset:   1%|‚ñè         | 1/70 [02:05<2:24:35, 125.74s/it]Loading dataset:   3%|‚ñé         | 2/70 [03:10<1:42:03, 90.05s/it] Loading dataset:   4%|‚ñç         | 3/70 [03:46<1:13:03, 65.43s/it]Loading dataset:   6%|‚ñå         | 4/70 [04:20<58:14, 52.95s/it]  Loading dataset:   7%|‚ñã         | 5/70 [04:21<36:50, 34.01s/it]Loading dataset:  24%|‚ñà‚ñà‚ñç       | 17/70 [04:48<05:53,  6.68s/it]Loading dataset:  26%|‚ñà‚ñà‚ñå       | 18/70 [04:48<05:17,  6.11s/it]Loading dataset:  27%|‚ñà‚ñà‚ñã       | 19/70 [04:49<04:37,  5.44s/it]Loading dataset:  29%|‚ñà‚ñà‚ñä       | 20/70 [05:33<09:09, 10.99s/it]Loading dataset:  30%|‚ñà‚ñà‚ñà       | 21/70 [05:34<07:36,  9.31s/it]Loading dataset:  31%|‚ñà‚ñà‚ñà‚ñè      | 22/70 [06:09<11:27, 14.33s/it]Loading dataset:  33%|‚ñà‚ñà‚ñà‚ñé      | 23/70 [06:38<13:40, 17.46s/it]Loading dataset:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 30/70 [06:41<03:51,  5.80s/it]Loading dataset:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 31/70 [07:19<06:19,  9.72s/it]Loading dataset:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 32/70 [07:36<05:48,  9.18s/it]Loading dataset:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 33/70 [07:41<06:25, 10.42s/it]Loading dataset:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 37/70 [07:49<03:26,  6.25s/it]Loading dataset:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 38/70 [08:11<04:35,  8.61s/it]Loading dataset:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 39/70 [08:11<03:40,  7.11s/it]Loading dataset:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 40/70 [08:50<06:44, 13.50s/it]Loading dataset:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 41/70 [09:37<10:13, 21.14s/it]Loading dataset:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 48/70 [10:44<04:48, 13.09s/it]Loading dataset:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 49/70 [10:56<04:32, 12.96s/it]Loading dataset:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 50/70 [11:04<04:04, 12.20s/it]Loading dataset:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 52/70 [11:36<04:00, 13.37s/it]Loading dataset:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 53/70 [11:37<03:08, 11.11s/it]Loading dataset:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 54/70 [11:37<02:22,  8.92s/it]Loading dataset:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 55/70 [11:37<01:44,  6.96s/it]Loading dataset:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 56/70 [11:47<01:46,  7.60s/it]Loading dataset:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 57/70 [11:47<01:14,  5.70s/it]Loading dataset:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 58/70 [12:06<01:51,  9.30s/it]Loading dataset:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 61/70 [12:19<00:59,  6.66s/it]Loading dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [12:19<00:00, 10.57s/it]
Loading dataset:   0%|          | 0/10 [00:00<?, ?it/s]Loading dataset:  10%|‚ñà         | 1/10 [01:24<12:37, 84.20s/it]Loading dataset:  20%|‚ñà‚ñà        | 2/10 [01:30<05:07, 38.42s/it]Loading dataset:  30%|‚ñà‚ñà‚ñà       | 3/10 [01:31<02:30, 21.45s/it]Loading dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [01:31<00:00,  9.18s/it]
  0%|          | 0/2500 [00:00<?, ?it/s]  0%|          | 0/2500 [00:07<?, ?it/s]
Traceback (most recent call last):
  File "/local/210406/src/main.py", line 64, in <module>
    main()
  File "/local/210406/src/main.py", line 46, in main
    train_single_epoch(model=model, optimizer=optimizer, train_loader=train_loader)
  File "/local/210406/src/training/train.py", line 22, in train_single_epoch
    loss.backward()
  File "/home/s1797743/.conda/envs/final/lib/python3.10/site-packages/torch/_tensor.py", line 478, in backward
    return handle_torch_function(
  File "/home/s1797743/.conda/envs/final/lib/python3.10/site-packages/torch/overrides.py", line 1551, in handle_torch_function
    result = torch_func_method(public_api, types, args, kwargs)
  File "/home/s1797743/.conda/envs/final/lib/python3.10/site-packages/monai/data/meta_tensor.py", line 268, in __torch_function__
    ret = super().__torch_function__(func, types, args, kwargs)
  File "/home/s1797743/.conda/envs/final/lib/python3.10/site-packages/torch/_tensor.py", line 1295, in __torch_function__
    ret = func(*args, **kwargs)
  File "/home/s1797743/.conda/envs/final/lib/python3.10/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home/s1797743/.conda/envs/final/lib/python3.10/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1024.00 MiB (GPU 0; 44.43 GiB total capacity; 42.49 GiB already allocated; 298.50 MiB free; 43.75 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: üöÄ View run old_32_512 at: https://wandb.ai/barisimre/Meeting/runs/nyle3s48
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230508_230610-nyle3s48/logs
