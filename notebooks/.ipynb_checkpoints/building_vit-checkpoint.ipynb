{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-21T14:46:51.713187Z",
     "start_time": "2023-04-21T14:46:50.095480Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<class 'monai.transforms.utility.array.AddChannel'>: Class `AddChannel` has been deprecated since version 0.8. please use MetaTensor data type and monai.transforms.EnsureChannelFirst instead.\n",
      "<class 'monai.transforms.utility.array.AsChannelFirst'>: Class `AsChannelFirst` has been deprecated since version 0.8. please use MetaTensor data type and monai.transforms.EnsureChannelFirst instead.\n"
     ]
    }
   ],
   "source": [
    "from src.model.my_model import MyModel\n",
    "from src.model.blocks import *\n",
    "from src.model.vit import DefaultViT\n",
    "import torch\n",
    "from src.constants import *\n",
    "from src.model.baselines import SWINUNETR, UNet\n",
    "import importlib\n",
    "import einops\n",
    "import time\n",
    "from src.data.data_loaders import get_loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(in_channels=1, patch_size=8, out_channels=3, skip_transformer=False, channels=(32, 32, 32, 32, 32),transformer_channels=8, embed_dim=256).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATES[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 70/70 [07:27<00:00,  6.39s/it] \n",
      "Loading dataset: 100%|██████████| 10/10 [00:28<00:00,  2.84s/it]\n"
     ]
    }
   ],
   "source": [
    "# train_loader, test_loader = get_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.training.train import train_single_epoch\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:iu0og69y) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>1.1703</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rich-snowball-1</strong> at: <a href='https://wandb.ai/barisimre/debug_2.0/runs/iu0og69y' target=\"_blank\">https://wandb.ai/barisimre/debug_2.0/runs/iu0og69y</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230422_164758-iu0og69y/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:iu0og69y). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/s1797743/thesis/final/AAAsegmentor/notebooks/wandb/run-20230422_165132-ysdt3qha</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/barisimre/debug_2.0/runs/ysdt3qha' target=\"_blank\">bright-firebrand-2</a></strong> to <a href='https://wandb.ai/barisimre/debug_2.0' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/barisimre/debug_2.0' target=\"_blank\">https://wandb.ai/barisimre/debug_2.0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/barisimre/debug_2.0/runs/ysdt3qha' target=\"_blank\">https://wandb.ai/barisimre/debug_2.0/runs/ysdt3qha</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 13s, sys: 1min 30s, total: 3min 44s\n",
      "Wall time: 31.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.196837534223284"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "wandb.init(\n",
    "    project=\"debug_2.0\",\n",
    "    entity=\"barisimre\",\n",
    ")\n",
    "\n",
    "train_single_epoch(model=model, optimizer=optimizer, train_loader=train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-21T14:46:53.307135Z",
     "start_time": "2023-04-21T14:46:51.716892Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "device= \"cuda\"\n",
    "\n",
    "img = torch.rand(8, 1, 128, 128, 128).to(device)\n",
    "mask = torch.rand(8, 3, 128, 128, 128).to(device)\n",
    "\n",
    "tokens = torch.rand(size=(4, 1024, 256)).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-21T14:46:53.422645Z",
     "start_time": "2023-04-21T14:46:53.309515Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model = MyModel(in_channels=1, patch_size=8, out_channels=3, skip_transformer=False, channels=(32, 32, 32, 32, 32),transformer_channels=8, embed_dim=256).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATES[0])\n",
    "torch.cuda.empty_cache()\n",
    "# other = UNet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-21T14:52:16.345016Z",
     "start_time": "2023-04-21T14:52:14.348755Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 128, 128, 128])\n",
      "CPU times: user 898 ms, sys: 101 ms, total: 999 ms\n",
      "Wall time: 987 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "out = model(img)\n",
    "loss = LOSS(out, mask)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "torch.cuda.synchronize()\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.rand(2, 1, 128, 128, 128).to(device)\n",
    "mask = torch.rand(2, 3, 128, 128, 128).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 32, 64, 64, 64])\n",
      "CPU times: user 326 ms, sys: 732 µs, total: 327 ms\n",
      "Wall time: 323 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Encoder\n",
    "for _ in range(10):\n",
    "    img = torch.rand(2, 1, 128, 128, 128).to(device)\n",
    "    conv = Down(1, 32).to(device)\n",
    "    encoder_out = conv(img)\n",
    "    torch.cuda.synchronize()\n",
    "print(encoder_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [torch.rand(size=([2, 8, 128, 128, 128])).to(device) for _ in range(10)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 256, 8, 8, 8])\n",
      "torch.Size([2, 256, 8, 8, 8])\n",
      "torch.Size([2, 256, 8, 8, 8])\n",
      "torch.Size([2, 256, 8, 8, 8])\n",
      "torch.Size([2, 256, 8, 8, 8])\n",
      "torch.Size([2, 256, 8, 8, 8])\n",
      "torch.Size([2, 256, 8, 8, 8])\n",
      "torch.Size([2, 256, 8, 8, 8])\n",
      "torch.Size([2, 256, 8, 8, 8])\n",
      "torch.Size([2, 256, 8, 8, 8])\n",
      "torch.Size([2, 512, 256])\n",
      "CPU times: user 39.1 ms, sys: 0 ns, total: 39.1 ms\n",
      "Wall time: 35.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ViT embed\n",
    "embedder =  ViTEmbedder(patch_size=16, in_channels=8, embed_dim=256).to(device)\n",
    "\n",
    "for i in range(10):\n",
    "    encoder_out = xs[i]\n",
    "    embedded = embedder(encoder_out)\n",
    "    torch.cuda.synchronize()\n",
    "    # print(embedded.shape)\n",
    "    embedded = einops.rearrange(embedded, \"b em x y z -> b (x y z) em\")\n",
    "print(embedded.shape)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [torch.rand(size=([2, 16000, 256])).to(device) for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 16000, 256])\n",
      "CPU times: user 778 ms, sys: 8.31 ms, total: 786 ms\n",
      "Wall time: 450 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "encoder_layer = torch.nn.TransformerEncoderLayer(d_model=256, nhead=8, dim_feedforward=256 * 2,\n",
    "                                                 dropout=0.1,\n",
    "                                                 activation=\"gelu\", layer_norm_eps=1e-5, batch_first=False,\n",
    "                                                 norm_first=False)\n",
    "\n",
    "encoder_norm = torch.nn.LayerNorm(256, eps=1e-5)\n",
    "vit = torch.nn.TransformerEncoder(encoder_layer, num_layers=12, norm=encoder_norm).to(device)\n",
    "\n",
    "for i in range(10):\n",
    "    tokens = xs[i]\n",
    "    \n",
    "    tokens_out = vit(tokens)\n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "print(tokens_out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [torch.rand(size=([2, 512, 256])).to(device) for _ in range(10)]\n",
    "xss = [torch.rand(size=([2, 256, 8, 8, 8])).to(device) for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lol\n",
      "lol2\n",
      "lol\n",
      "lol2\n",
      "torch.Size([2, 8, 128, 128, 128])\n",
      "CPU times: user 1min 33s, sys: 711 ms, total: 1min 34s\n",
      "Wall time: 1min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "conv = nn.ConvTranspose3d(kernel_size=16, stride=16, in_channels=256, out_channels=8).to(device)\n",
    "\n",
    "for i in range(2):\n",
    "    encoder_out = torch.rand(size=([2, 512, 256])).to(device)\n",
    "    reshaped = encoder_out.view(-1, 8, 8, 8, encoder_out.size(-1))\n",
    "    encoder_out = reshaped.permute(0, 4, 1, 2, 3)\n",
    "    torch.cuda.synchronize()\n",
    "    embedded = conv(encoder_out)\n",
    "    torch.cuda.synchronize()\n",
    "print(embedded.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 256, 8, 8, 8])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = einops.rearrange(torch.rand(size=([4, 512, 256]), device=device), \"b (x y z) em -> b em x y z\", x=8, y=8, z=8)\n",
    "torch.cuda.synchronize()\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 128, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "conv1 = nn.ConvTranspose3d(kernel_size=16, stride=16, in_channels=256, out_channels=8).to(device)\n",
    "out = conv1(out)\n",
    "out = conv1(torch.rand(size=[[4, 256, 8, 8, 8]]))\n",
    "torch.cuda.synchronize()\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.69 ms, sys: 57 µs, total: 4.75 ms\n",
      "Wall time: 2.5 ms\n"
     ]
    }
   ],
   "source": [
    "example = torch.rand(size=([2, 512, 256])).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 256, 8, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "reshaped = example.view(-1, 8, 8, 8, example.size(-1))\n",
    "out = reshaped.permute(0, 4, 1, 2, 3)\n",
    "torch.cuda.synchronize()\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import einops\n",
    "import time\n",
    "# import wandb\n",
    "\n",
    "# wandb.init(\n",
    "#     project=\"debug_cluster\",\n",
    "#     entity=\"barisimre\",\n",
    "# )\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "print(f\"Python version {sys.version}\")\n",
    "print(f\"Torch version {torch.__version__}\")\n",
    "print(f\"Cuda version {torch.version.cuda}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(torch.cuda.current_device())}\\n\")\n",
    "\n",
    "\n",
    "sample_input = torch.rand(size=([2, 512, 256])).to(device)\n",
    "sample_label = torch.rand(size=([2, 8, 128, 128, 128])).to(device)\n",
    "\n",
    "conv1 = nn.ConvTranspose3d(kernel_size=16, stride=16, in_channels=256, out_channels=8).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(params=conv1.parameters(), lr=0.0001)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "start_time = time.time()\n",
    "\n",
    "out = einops.rearrange(sample_input, \"b (x y z) em -> b em x y z\", x=8, y=8, z=8)\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "print(f'Rearrange done: {time.time() - start_time:.6f} seconds')\n",
    "\n",
    "out = conv1(out)\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "print(f'Convolution done: {time.time() - start_time:.6f} seconds')\n",
    "\n",
    "loss = loss_fn(out, sample_label)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "print(f'Backprop done: {time.time() - start_time:.6f} seconds')\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "print(out.shape)\n",
    "\n",
    "end_time = time.time()\n",
    "time_elapsed = end_time - start_time\n",
    "\n",
    "print(f'Total time taken: {time_elapsed:.6f} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n",
      "11.6\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Apr 22 13:11:11 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.86.01    Driver Version: 515.86.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A40          On   | 00000000:3B:00.0 Off |                    0 |\n",
      "|  0%   43C    P0    79W / 300W |   6313MiB / 46068MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A40          On   | 00000000:5E:00.0 Off |                    0 |\n",
      "|  0%   36C    P8    32W / 300W |      0MiB / 46068MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A40          On   | 00000000:B1:00.0 Off |                    0 |\n",
      "|  0%   34C    P8    29W / 300W |      0MiB / 46068MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA RTX A4500    On   | 00000000:D9:00.0 Off |                  Off |\n",
      "| 30%   33C    P8    17W / 200W |      1MiB / 20470MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A   2176782      C   ...da/envs/my_env/bin/python     6311MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"nvidia-smi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 128, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "conv1 = nn.ConvTranspose3d(kernel_size=16, stride=16, in_channels=256, out_channels=8).to(device)\n",
    "out = einops.rearrange(torch.rand(size=([4, 512, 256]), device=device), \"b (x y z) em -> b em x y z\", x=8, y=8, z=8)\n",
    "out = conv1(out)\n",
    "torch.cuda.synchronize()\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = torch.rand(size=([4, 512, 256])).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.cuda.FloatTensor'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_input.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
